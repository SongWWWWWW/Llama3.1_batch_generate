{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: modelscope in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (1.16.1)\n",
      "Requirement already satisfied: requests>=2.25 in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (from modelscope) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (from modelscope) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.26 in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (from modelscope) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (from requests>=2.25->modelscope) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (from requests>=2.25->modelscope) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages (from requests>=2.25->modelscope) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/wcc_dp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 855/855 [00:00<00:00, 1.86kB/s]\n",
      "Downloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 128B/s]\n",
      "Downloading: 100%|██████████| 15.0G/15.0G [01:27<00:00, 184MB/s]   \n",
      "Downloading: 100%|██████████| 184/184 [00:00<00:00, 627B/s]\n",
      "Downloading: 100%|██████████| 7.45k/7.45k [00:00<00:00, 26.8kB/s]\n",
      "Downloading: 100%|██████████| 4.63G/4.63G [00:42<00:00, 117MB/s] \n",
      "Downloading: 100%|██████████| 4.66G/4.66G [00:28<00:00, 174MB/s] \n",
      "Downloading: 100%|██████████| 4.58G/4.58G [00:29<00:00, 167MB/s] \n",
      "Downloading: 100%|██████████| 1.09G/1.09G [00:11<00:00, 99.6MB/s]\n",
      "Downloading: 100%|██████████| 23.4k/23.4k [00:00<00:00, 73.3kB/s]\n",
      "Downloading: 100%|██████████| 199/199 [00:00<00:00, 541B/s]\n",
      "Downloading: 100%|██████████| 40.5k/40.5k [00:00<00:00, 106kB/s]\n",
      "Downloading: 100%|██████████| 296/296 [00:00<00:00, 804B/s]\n",
      "Downloading: 100%|██████████| 8.66M/8.66M [00:00<00:00, 10.4MB/s]\n",
      "Downloading: 100%|██████████| 2.08M/2.08M [00:00<00:00, 4.82MB/s]\n",
      "Downloading: 100%|██████████| 54.1k/54.1k [00:00<00:00, 195kB/s]\n",
      "Downloading: 100%|██████████| 4.58k/4.58k [00:00<00:00, 16.5kB/s]\n"
     ]
    }
   ],
   "source": [
    "! pip install modelscope\n",
    "import torch\n",
    "from modelscope import snapshot_download, AutoModel, AutoTokenizer\n",
    "import os\n",
    "model_dir = snapshot_download('LLM-Research/Meta-Llama-3.1-8B-Instruct', cache_dir='/root/autodl-tmp', revision='master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I don\\'t have a personal name, but you can call me \"Assistant\" or \"AI Assistant\" if you like. I\\'m here to provide information and help with any questions you may have.',\n",
       " \"SSH stands for Secure Shell. It's a secure protocol used to access and manage remote computers, servers, and other network devices over the internet or a local network. SSH allows users to execute commands, transfer files, and access remote systems securely, using encryption to protect the data and communication.\\n\\nSSH provides a secure way to:\\n\\n1. **Remote access**: Connect to a remote server or device using a secure channel, replacing traditional insecure protocols like Telnet or FTP.\\n2. **Command execution**: Execute commands on a remote system, just like you would on a local system.\\n3. **File transfer**: Transfer files between local and remote systems using secure protocols like SFTP (Secure File Transfer Protocol).\\n4. **Remote desktop**: Access a remote desktop session, allowing you to interact with the remote system as if you were sitting in front of it.\\n\\nSSH uses encryption to protect data in transit, making it more secure than unencrypted protocols like Telnet or FTP. It also supports various authentication methods, such as password authentication, public key authentication, and Kerberos authentication.\\n\\nSome common SSH commands and uses include:\\n\\n* `ssh user@remote-host`: Connect to a remote host as a specific user.\\n* `ssh-keygen`: Generate a pair of SSH keys for authentication.\\n* `scp`: Securely copy files between local and remote systems.\\n* `sftp`: Securely transfer files between local and remote systems.\\n* `ssh-agent`: Start the secure shell agent, which manages SSH connections and authentication.\\n\\nSSH is widely used by system administrators, developers, and anyone who needs to manage remote systems securely.\",\n",
       " 'LLM stands for Large Language Model. It\\'s a type of artificial intelligence (AI) designed to process and generate human-like language. LLMs are trained on vast amounts of text data, allowing them to learn patterns, relationships, and context within language.\\n\\nLarge Language Models are typically trained using a type of machine learning called deep learning, which involves neural networks with many layers. These models are \"large\" in the sense that they have a massive number of parameters (weights and biases) that are adjusted during training to optimize their performance.\\n\\nSome key characteristics of LLMs include:\\n\\n1. **Language understanding**: LLMs can comprehend natural language, including nuances, idioms, and context-dependent expressions.\\n2. **Text generation**: LLMs can generate human-like text, including responses to questions, answers to prompts, and even entire articles or stories.\\n3. **Language translation**: LLMs can translate text from one language to another, often with high accuracy.\\n4. **Summarization**: LLMs can summarize long pieces of text into shorter, more digestible versions.\\n5. **Conversational dialogue**: LLMs can engage in conversations, responding to user input and adapting to the context of the conversation.\\n\\nLLMs have many applications, including:\\n\\n1. **Virtual assistants**: LLMs power virtual assistants like Siri, Alexa, and Google Assistant.\\n2. **Chatbots**: LLMs are used in chatbots to provide customer support, answer frequently asked questions, and engage with customers.\\n3. **Language translation**: LLMs are used in translation software to translate text and speech in real-time.\\n4. **Content generation**: LLMs can generate content, such as articles, social media posts, and even entire books.\\n5. **Research**: LLMs are used in research to analyze and understand language patterns, sentiment analysis, and topic modeling.\\n\\nSome popular examples of LLMs include:\\n\\n1. **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google, BERT is a widely used LLM for natural language processing tasks.\\n2. **RoBERTa (Robustly Optimized BERT Pretraining Approach)**: An improved version of BERT, developed by Facebook AI.\\n3. **Language Model 3 (LLa']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_completion(prompts):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\"prompts\": prompts}\n",
    "    response = requests.post(url='http://127.0.0.1:6006', headers=headers, data=json.dumps(data))\n",
    "    return response.json()['response']\n",
    "\n",
    "\n",
    "# def format_prompt(demonstrations:list,test_demonstration):\n",
    "\n",
    "#     pass\n",
    "prompts = [\n",
    "    \"what's your name?\",\n",
    "    \"what's is ssh?\",\n",
    "    \"what's is LLM?\"\n",
    "]\n",
    "get_completion(prompts=prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'positive'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{\\n    \"category\": \"positive\"\\n}'\n",
    "import json\n",
    "json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0, 0, 0]\n",
      "3\n",
      "[0, 0, 0]\n",
      "6\n",
      "[0, 0, 0]\n",
      "9\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "train = [0 for i in range(10)]\n",
    "for i in range(0, 10, 3):\n",
    "    print(i)\n",
    "    batch_data = train[i:i+3]\n",
    "    print(batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = [0 for i in range(10)]\n",
    "train[9:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wcc_dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
